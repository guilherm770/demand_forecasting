from __future__ import annotations
import argparse, json, os
from pathlib import Path
from datetime import datetime
import psutil
import gc
import warnings

import numpy as np
import pandas as pd
from joblib import dump
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.model_selection import TimeSeriesSplit

from scripts.utils import load_params, load_processed, split_train_test_by_days
from scripts.metrics import summarize

import mlflow

# Suprimir warnings de sklearn que est√£o aparecendo
warnings.filterwarnings('ignore', message='invalid value encountered in divide')

def check_memory_usage():
    """Monitora uso de mem√≥ria e limpa garbage collection se necess√°rio"""
    memory_percent = psutil.virtual_memory().percent
    if memory_percent > 80:
        gc.collect()
        print(f"‚ö†Ô∏è  Alto uso de mem√≥ria ({memory_percent:.1f}%) - executando garbage collection")
    return memory_percent

def sample_data_if_needed(df: pd.DataFrame, params: dict) -> pd.DataFrame:
    """Aplica sampling nos dados se configurado para modo desenvolvimento"""
    training_config = params.get("training", {})
    
    if not training_config.get("development_mode", False):
        return df
    
    original_size = len(df)
    
    # Aplicar sample_fraction
    sample_fraction = training_config.get("sample_fraction", 1.0)
    if sample_fraction < 1.0:
        df = df.sample(frac=sample_fraction, random_state=42)
        print(f"üìä Dados reduzidos por fra√ß√£o: {original_size:,} ‚Üí {len(df):,} ({sample_fraction:.2%})")
    
    # Aplicar max_samples
    max_samples = training_config.get("max_samples")
    if max_samples and len(df) > max_samples:
        df = df.sample(n=max_samples, random_state=42)
        print(f"üìä Dados limitados: {len(df):,} amostras (m√°ximo: {max_samples:,})")
    
    if len(df) != original_size:
        print(f"‚úÖ Dataset final: {len(df):,} amostras ({len(df)/original_size:.2%} do original)")
    
    return df

def build_pipeline(model_name: str, params: dict, numeric_cols, cat_cols):
    from sklearn.ensemble import RandomForestRegressor
    from xgboost import XGBRegressor

    training_config = params.get("training")
    # Usar StandardScaler mais simples para desenvolvimento
    if training_config.get("development_mode"):
        scaler = StandardScaler(with_mean=False)
    else:
        scaler = StandardScaler()

    pre = ColumnTransformer(
        transformers=[
            ("num", scaler, numeric_cols),
            ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_cols),
        ],
        remainder="drop"
    )

    if model_name == "rf":
        rf_params = training_config.get("rf")
        print(rf_params)
        # Ajustar n_jobs para n√£o sobrecarregar
        max_jobs = psutil.cpu_count() - 1 if psutil.cpu_count() > 1 else 1
        if rf_params.get("n_jobs") == -1 or rf_params.get("n_jobs") > max_jobs:
            rf_params["n_jobs"] = max_jobs
            print(f"üîß Ajustado n_jobs para {max_jobs}")
        
        model = RandomForestRegressor(
            n_estimators=rf_params.get("n_estimators"),
            max_depth=rf_params.get("max_depth"),
            min_samples_split=rf_params.get("min_samples_split"),
            min_samples_leaf=rf_params.get("min_samples_leaf"),
            max_features=rf_params.get("max_features"),
            n_jobs=rf_params.get("n_jobs"),
            random_state=training_config.get("random_state"),
        )
    elif model_name == "xgb":
        xgb_params = params["training"]["xgb"].copy()
        max_jobs = psutil.cpu_count() - 1 if psutil.cpu_count() > 1 else 1
        if xgb_params.get("n_jobs", -1) == -1 or xgb_params.get("n_jobs", 1) > max_jobs:
            xgb_params["n_jobs"] = max_jobs
            print(f"üîß Ajustado n_jobs para {max_jobs}")
        
        model = XGBRegressor(
            n_estimators=xgb_params["n_estimators"],
            learning_rate=xgb_params["learning_rate"],
            max_depth=xgb_params["max_depth"],
            subsample=xgb_params["subsample"],
            colsample_bytree=xgb_params["colsample_bytree"],
            reg_lambda=xgb_params["reg_lambda"],
            reg_alpha=xgb_params.get("reg_alpha", 0.0),
            n_jobs=xgb_params["n_jobs"],
            random_state=params["training"]["random_state"],
            tree_method="hist",
        )
    else:
        raise ValueError(f"Modelo n√£o suportado: {model_name}")

    return Pipeline([("pre", pre), ("model", model)])

def setup_local_mlflow(experiment_name: str):
    """Configura MLflow para funcionar apenas localmente"""
    try:
        # Usar tracking URI local por padr√£o
        local_uri = "file:./mlruns"
        mlflow.set_tracking_uri(local_uri)
        
        # Testar se consegue conectar
        mlflow.search_experiments(max_results=1)
        
        mlflow.set_experiment(experiment_name)
        print(f"‚úÖ MLflow configurado localmente: {local_uri}")
        print(f"üìä Experimento: {experiment_name}")
        return True
        
    except Exception as e:
        print(f"‚ö†Ô∏è  MLflow desabilitado: {e}")
        return False

def main(config_path: str = "params.yaml", model_override: str | None = None, experiment: str | None = None):
    print(f"üöÄ Iniciando treinamento com configura√ß√£o: {config_path}")
    
    # Monitorar recursos iniciais
    initial_memory = psutil.virtual_memory().percent
    available_gb = psutil.virtual_memory().available / (1024**3)
    print(f"üíæ Mem√≥ria dispon√≠vel: {available_gb:.1f}GB ({initial_memory:.1f}% em uso)")
    
    # Carregar par√¢metros
    params = load_params(config_path)

    # Configurar MLflow local
    experiment_name = experiment or params["mlflow"]["experiment"]
    mlflow_enabled = setup_local_mlflow(experiment_name)

    # Carregar dados
    print("üìÅ Carregando dados processados...")
    df = load_processed(train=True)
    print(f"üìä Dados originais: {len(df):,} linhas, {len(df.columns)} colunas")
    
    # Aplicar sampling se necess√°rio
    df = sample_data_if_needed(df, params)
    check_memory_usage()

    # Configura√ß√£o de treinamento
    tconf = params["training"]
    date_col = tconf["date_col"]
    target   = tconf["target"]
    id_cols  = tconf["id_cols"]
    drop_cols= set([target, date_col] + tconf.get("features_to_drop", []))

    # Preparar features
    all_cols = [c for c in df.columns if c not in drop_cols]
    cat_cols = [c for c in all_cols if str(df[c].dtype) in ("object", "category") or c in id_cols]
    num_cols = [c for c in all_cols if c not in cat_cols]
    
    print(f"üîß Features: {len(all_cols)} total ({len(num_cols)} num√©ricas, {len(cat_cols)} categ√≥ricas)")

    # Split temporal
    print(f"‚úÇÔ∏è  Split temporal: holdout de {tconf['test_size_days']} dias")
    train_df, test_df = split_train_test_by_days(df, date_col, tconf["test_size_days"])
    print(f"üìä Train: {len(train_df):,} | Holdout: {len(test_df):,}")

    X_train = train_df[all_cols]
    y_train = train_df[target]
    X_test  = test_df[all_cols] if len(test_df) > 0 else pd.DataFrame()
    y_test  = test_df[target] if target in test_df.columns and len(test_df) > 0 else None

    # Liberar mem√≥ria
    del df, train_df, test_df
    gc.collect()
    check_memory_usage()

    # Construir pipeline
    model_name = model_override or tconf["model"]
    print(f"ü§ñ Modelo: {model_name}")
    pipe = build_pipeline(model_name, params.copy(), num_cols, cat_cols)

    # Cross-validation temporal
    cv_config = params["cv"]
    n_splits = cv_config["n_splits"]
    print(f"üîÑ Cross-validation temporal: {n_splits} folds")
    
    tscv = TimeSeriesSplit(n_splits=n_splits, gap=cv_config.get("gap", 0))

    cv_metrics = []
    for fold, (tr_idx, va_idx) in enumerate(tscv.split(X_train), 1):
        print(f"  üìÅ Fold {fold}/{n_splits}")
        
        Xt, yt = X_train.iloc[tr_idx], y_train.iloc[tr_idx]
        Xv, yv = X_train.iloc[va_idx], y_train.iloc[va_idx]
        
        pipe_fold = build_pipeline(model_name, params, num_cols, cat_cols)
        pipe_fold.fit(Xt, yt)
        preds = pipe_fold.predict(Xv)
        fold_metrics = summarize(yv.values, preds)
        cv_metrics.append(fold_metrics)
        
        print(f"    MAE: {fold_metrics['mae']:.4f}, RMSE: {fold_metrics['rmse']:.4f}")
        
        # Limpeza de mem√≥ria
        del pipe_fold, Xt, yt, Xv, yv, preds
        gc.collect()

    # Resumo do CV
    cv_summary = {k: float(np.mean([m[k] for m in cv_metrics])) for k in cv_metrics[0].keys()}
    print(f"‚úÖ CV m√©dio - MAE: {cv_summary['mae']:.4f}, RMSE: {cv_summary['rmse']:.4f}")

    # Treino final
    print("üèãÔ∏è  Treinamento final no dataset completo...")
    pipe.fit(X_train, y_train)

    # Avalia√ß√£o no holdout
    holdout_metrics = {}
    if y_test is not None and len(X_test) > 0:
        print("üéØ Avalia√ß√£o no holdout...")
        preds = pipe.predict(X_test)
        holdout_metrics = summarize(y_test.values, preds)
        print(f"üéØ Holdout - MAE: {holdout_metrics['mae']:.4f}, RMSE: {holdout_metrics['rmse']:.4f}")

    # Persist√™ncia local
    ts = datetime.now().strftime("%Y%m%d-%H%M%S")
    Path("artifacts/models").mkdir(parents=True, exist_ok=True)
    
    config_name = Path(config_path).stem
    model_path = Path(f"artifacts/models/model-{model_name}-{config_name}-{ts}.pkl")
    
    print(f"üíæ Salvando modelo: {model_path}")
    dump(pipe, model_path)

    # Salvar m√©tricas
    Path("artifacts/metrics").mkdir(parents=True, exist_ok=True)
    
    with open("artifacts/metrics/cv_metrics.json", "w") as f:
        json.dump(cv_summary, f, indent=2)
    
    if holdout_metrics:
        with open("artifacts/metrics/holdout_metrics.json", "w") as f:
            json.dump(holdout_metrics, f, indent=2)

    # MLflow logging (apenas se estiver funcionando)
    if mlflow_enabled:
        try:
            run_name = f"{model_name}-{config_name}-{ts}"
            print(f"üìä Logando no MLflow: {run_name}")
            
            with mlflow.start_run(run_name=run_name):
                # Par√¢metros b√°sicos
                log_params = {
                    "model": model_name,
                    "config_file": config_name,
                    "features_total": len(all_cols),
                    "num_cols": len(num_cols),
                    "cat_cols": len(cat_cols),
                    "test_size_days": tconf["test_size_days"],
                    "cv_folds": n_splits,
                    "train_samples": len(X_train),
                    "development_mode": tconf.get("development_mode", False),
                }
                
                # Par√¢metros do modelo
                if model_name == "rf" and "rf" in tconf:
                    log_params.update({f"rf_{k}": v for k, v in tconf["rf"].items()})
                elif model_name == "xgb" and "xgb" in tconf:
                    log_params.update({f"xgb_{k}": v for k, v in tconf["xgb"].items()})

                # Par√¢metros de recursos
                log_params.update({
                    "available_memory_gb": available_gb,
                    "cpu_count": psutil.cpu_count(),
                    "sample_fraction": tconf.get("sample_fraction", 1.0),
                })

                mlflow.log_params(log_params)

                # M√©tricas
                mlflow.log_metrics({f"cv_{k}": v for k, v in cv_summary.items()})
                if holdout_metrics:
                    mlflow.log_metrics({f"holdout_{k}": v for k, v in holdout_metrics.items()})

                # Artefatos apenas localmente (sem S3)
                try:
                    mlflow.log_artifact(str(model_path))
                    mlflow.log_artifact(config_path)
                except Exception as e:
                    print(f"‚ö†Ô∏è  N√£o foi poss√≠vel fazer log dos artefatos: {e}")
                    print("üìù Modelo salvo apenas localmente")

        except Exception as e:
            print(f"‚ö†Ô∏è  Erro no MLflow: {e}")
            print("üìù M√©tricas salvas apenas localmente")

    final_memory = psutil.virtual_memory().percent
    print(f"‚úÖ Treinamento conclu√≠do!")
    print(f"üíæ Uso de mem√≥ria: {initial_memory:.1f}% ‚Üí {final_memory:.1f}%")
    print(f"üèÜ Modelo salvo: {model_path}")
    
    # Resumo final
    print(f"\nüìä RESUMO FINAL:")
    print(f"   üéØ CV - MAE: {cv_summary['mae']:.4f}, RMSE: {cv_summary['rmse']:.4f}")
    if holdout_metrics:
        print(f"   üéØ Holdout - MAE: {holdout_metrics['mae']:.4f}, RMSE: {holdout_metrics['rmse']:.4f}")

if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="Treinamento local sem depend√™ncias de cloud")
    ap.add_argument("--config", help="Arquivo de configura√ß√£o", default="params.yaml")
    ap.add_argument("--model", help="rf|xgb (override do config)", default=None)
    ap.add_argument("--experiment", help="Nome do experimento MLflow", default=None)
    args = ap.parse_args()
    
    main(config_path=args.config, model_override=args.model, experiment=args.experiment)