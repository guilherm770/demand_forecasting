#!/usr/bin/env python3
"""
Script orquestrador que executa pipeline completo com tratamento
de erros robusto e logging detalhado.
"""

import sys
import logging
from pathlib import Path
import yaml
from datetime import datetime

# Importar m√≥dulos do sistema
from download_data import download_dataset
from data_validation import main as validate_data
from process_data import DataProcessor

def setup_logging():
    """Configura logging centralizado do sistema."""
    log_dir = Path('logs')
    log_dir.mkdir(exist_ok=True)
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / 'pipeline.log'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    return logging.getLogger('FullPipeline')

def load_pipeline_config() -> dict:
    """Carrega configura√ß√£o completa do pipeline."""
    config_path = Path('config/pipeline.yaml')
    
    if config_path.exists():
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    
    # Configura√ß√£o padr√£o
    return {
        'pipeline': {
            'skip_download': False,
            'skip_validation': False,
            'run_monitoring': True,
            'fail_on_error': True
        },
        'notifications': {
            'on_success': True,
            'on_failure': True
        }
    }

def run_full_pipeline():
    """
    Executa pipeline completo end-to-end com orquestra√ß√£o
    inteligente e recupera√ß√£o de erros.
    """
    logger = setup_logging()
    config = load_pipeline_config()
    
    pipeline_start = datetime.now()
    logger.info("üöÄ Iniciando pipeline completo...")
    
    try:
        # Fase 1: Download de dados
        if not config['pipeline']['skip_download']:
            logger.info("üì• Fase 1: Download de dados")
            download_dataset()
            logger.info("‚úÖ Download conclu√≠do")
        else:
            logger.info("‚è≠Ô∏è Download pulado conforme configura√ß√£o")
        
        # Fase 2: Valida√ß√£o
        if not config['pipeline']['skip_validation']:
            logger.info("üîç Fase 2: Valida√ß√£o de dados")
            validate_data()
            logger.info("‚úÖ Valida√ß√£o conclu√≠da")
        else:
            logger.info("‚è≠Ô∏è Valida√ß√£o pulada conforme configura√ß√£o")
        
        # Fase 3: Processamento
        logger.info("üîß Fase 3: Processamento e feature engineering")
        processor = DataProcessor()
        processor.run_full_pipeline()
        logger.info("‚úÖ Processamento conclu√≠do")
        
        # Sucesso
        pipeline_duration = datetime.now() - pipeline_start
        logger.info(f"üéâ Pipeline conclu√≠do com sucesso em {pipeline_duration}")
        
        if config['notifications']['on_success']:
            _send_success_notification(pipeline_duration)
        
        return True
        
    except Exception as e:
        pipeline_duration = datetime.now() - pipeline_start
        logger.error(f"‚ùå Pipeline falhou ap√≥s {pipeline_duration}: {str(e)}")
        
        if config['notifications']['on_failure']:
            _send_failure_notification(str(e), pipeline_duration)
        
        if config['pipeline']['fail_on_error']:
            sys.exit(1)
        
        return False

def _send_success_notification(duration):
    """Envia notifica√ß√£o de sucesso (placeholder para integra√ß√£o)."""
    print(f"‚úÖ SUCESSO: Pipeline conclu√≠do em {duration}")

def _send_failure_notification(error, duration):
    """Envia notifica√ß√£o de falha (placeholder para integra√ß√£o)."""  
    print(f"‚ùå FALHA: Pipeline falhou ap√≥s {duration} - {error}")

if __name__ == "__main__":
    run_full_pipeline()